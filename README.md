<br />
<div align="center">

  <h3 align="center">Sistemas Distribuidos: Tarea 03</h3>

  <p align="center">
    Fernando Bur√≥n, Felipe Condore
  </p>
 
</div>

## Acerca del proyecto

El objetivo de esta tarea consiste en poner en pr√°ctica el concepto de replicaci√≥n en bases de datos utilizando Cassandra


### üõ† Constru√≠do con:

Esta secci√≥n muestra las tecnolog√≠as con las que fue constru√≠do el proyecto.

* [Apache Cassandra](https://cassandra.apache.org/_/index.html)
* [Python](https://www.python.org)
* [Docker](https://www.docker.com)


## :octocat: Comenzando

<p allign="center">
<iframe width="1134" height="638" src="https://www.youtube.com/embed/IHcoLog6azg" title="Lo ha DESTROZADO!!!!! Xperia 1 IV vs iPhone 13 Pro Max **TEST A CIEGAS**" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>
Para iniciar el proyecto, primero hay que copiar el repositorio `git clone https://github.com/CondePoponcio/SD-T3-cassandra .` y escribir el siguiente comando en la consola:
* docker
```sh
docker-compose build
```
Para que los contenedores se inician en el ambiente local se utiliza el siguiente comando en la consola:
* docker
```sh
docker-compose up -d
```
Los tiempos de iniciaci√≥n son extensos debido a la alta demanda de c√≥mputo para los nodos de Cassandra

### Pre-Requisitos

Tener Docker y Docker Compose instalado
* [Installation Guide](https://docs.docker.com/compose/install/)


## ü§ù Uso

La aplicaci√≥n tiene una API dispoble en el puerto 3000

### Create
Genera una receta para un paciente espec√≠fico
```sh
curl --location --request POST http://localhost:3000/create \
--header 'Content-Type: application/json' \
--data-raw '{
    "nombre": "Cosme", 
    "apellido": "Fulanito",
    "rut": "19650228-9",
    "email": "fcondore@gmail.com",
    "fecha_nacimiento": "1998-08-28",
    "comentario": "Nada en particular",
    "farmacos": "Su paracetamil",
    "doctor": "Dr. Simi"
}'
```
#### Response example
```json
{
  "status":"success"
}
```

### Edit
Edita una receta en espec√≠fico
```sh
curl ‚àí‚àílocation ‚àí‚àírequest GET http://localhost:3000/edit
```
#### 
- ‚òÑ M√âTODO: GET
#### Response
```js
{
    "users-blocked":[
      "user1",
      "user2"
    ]
}
```
## ‚ùî Preguntas

### 1. ¬øPor qu√© Kafka funciona bien en este escenario?
Kafka es un software que permite el flujo y env√≠o de informaci√≥n en gran volumen a trav√©s de su sistema de t√≥picos (brokers). Esto √∫ltimo permite a los servicios de Login y Bloqueo trabajar de manera as√≠ncrona gracias al modelo productor/consumidor, dado que el servicio de Login es capaz de informar en el t√≥pico de kafka cuales son las cuentas que han tratado de iniciar sesi√≥n de manera fallida, sin necesidad de esperar a que el servicio de bloqueo realice alguna acci√≥n, puesto que kafka se encarga de almacenar esto en el t√≥pico el cual puede ser consumido por el servicio de Bloqueo en cualquier otro momento. 

Esto se traduce en un menor tiempo de respuesta para el usuario que est√© utilizando el cliente o aplicaci√≥n, ya que de no utilizar kafka la aplicaci√≥n estar√≠a esperando la respuesta del servicio de bloqueo (parecido a un modelo cliente/servidor) que en t√©rminos de escalabilidad resulta ineficiente, generando un cuello de botella que colapsar√≠a este servicio.

### 2. Basado en las tecnolog√≠as que usted tiene a su disposici√≥n (Kafka, backend) ¬øQu√© har√≠a usted para manejar una gran cantidad de usuarios al mismo tiempo?
Una opci√≥n inicial ser√≠a escalar kafka con m√°s brokers o equipos de manera distribuida para lograr comunicar una mayor cantidad de datos en tiempo real. Adicional a esto √∫ltimo, tambi√©n ser√≠a una buena opci√≥n distribuir el servicio de bloqueos agregando los siguientes servicios.

####
- Apache Flink: Flink es una herramienta de procesamiento de flujo en tiempo real y de c√≥digo abierto, cuya funcionalidad radica en el procesamiento de m√∫ltiples tareas realizas simult√°neamente en tiempo real, basado en alg√∫n tipo de input que provean datos y output donde se escribir o guardar los resultados obtenidos de estos procesamientos. Esta herramienta es ideal, puesto que nos permitir√≠a consumir el t√≥pico de kafka que contiene la lista de logins de usuarios, y determinar en tiempo real cuales cuentas deber√°n ser bloquedas.

- Redis: Es una base de datos en memoria NoSQL que se usa principalmente para la obtenci√≥n de warmdata. En este servicio se almacenar√≠an los resultados tras el procesamiento del servicio de flink, los cuales ser√≠an consumidos a trav√©s de la API del servicio de bloqueo.
####

A partir de esta arquitectura, ser√° posible manejar una gran cantidad de usuarios en tiempo real, puesto que el servicio de bloqueo solamente accede a los datos almacenados en cache (Redis). El trabajo de procesamiento y an√°lisis para determinar en el tiempo cuales cuentas corresponde a ser bloqueadas es llevado a cabo por Flink. Evitando lecturas y escrituras de archivos de manera ineficiente que solo empeora el rendimiento del sistema.

## ‚Ñπ Informaci√≥n Importante
El uso de las im√°genes de [Bitnami](https://hub.docker.com/u/bitnami) fueron reemplazadas por [wurstmeister](https://hub.docker.com/u/wurstmeister) por el simple hecho de que la utilizaci√≥n de [AIOKafka](https://github.com/aio-libs/aiokafka) no permit√≠a establecer una conexi√≥n con el contenedor de Kafka. Esta librer√≠a de Python permite utilizar Kafka de manera asincr√≥nica, exactamente lo que se requer√≠a para combinar Flask con un KafkaProducer. Para el api de bloqueo se us√≥ un KafkaProducer as√≠ncrono basado en la contribuci√≥n de trabajo de [NimzyMaina](https://github.com/NimzyMaina/flask_kafka).
